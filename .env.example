# term-trace Environment Configuration
# Copy this file to .env and customize as needed

# Base directory for all term-trace data (default: ~/.termtrace)
# TERMTRACE_BASE_DIR=/path/to/custom/dir

# API Endpoints
# OPENAI_API_URL=https://api.openai.com/v1/chat/completions
# GITHUB_MODELS_API_URL=https://models.github.ai/inference/chat/completions
# HUGGINGFACE_API_URL_TEMPLATE=https://router.huggingface.co/hf-inference/models/{model}

# API Keys
# OPENAI_API_KEY=sk-xxxxx
# GITHUB_TOKEN=ghp_xxxxx
# HUGGINGFACE_TOKEN=hf_xxxxx
# AZURE_OPENAI_KEY=xxxxx

# Default Model Names
# OPENAI_MODEL=gpt-3.5-turbo
# GITHUB_MODEL=xai/grok-3-mini
# HF_MODEL_NAME=sshleifer/distilbart-cnn-12-6

# API Timeouts (seconds)
# TERMTRACE_API_TIMEOUT=60

# Entry Limits for Summarization
# TERMTRACE_MAX_ENTRIES_HF=60
# TERMTRACE_MAX_ENTRIES_GENERIC=80

# LLM Generation Parameters
# TERMTRACE_TEMPERATURE=0.2
# TERMTRACE_MAX_TOKENS=300

# Shell Configuration
# TERMTRACE_SHELL_RC=~/.zshrc

# Google OAuth Configuration
# GOOGLE_CLIENT_SECRET=/path/to/client_secret.json

# Generic LLM Configuration (for custom endpoints)
# LLM_API_URL=https://custom-api.com/v1/chat/completions
# LLM_TOKEN_ENV_VAR=MY_API_TOKEN
# LLM_MODEL_NAME=my-model-name
